{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af025276-00b6-4c00-aa81-cdab89f267ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 15:50:26.665845: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/slurm-20.11.0/lib64:/opt/slurm/pe2/slurm/centos7/lib64:/opt/slurm/slurm-20.11.0/lib64:/opt/slurm/slurm-20.11.0/lib64:\n",
      "2023-06-23 15:50:26.666020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/slurm-20.11.0/lib64:/opt/slurm/pe2/slurm/centos7/lib64:/opt/slurm/slurm-20.11.0/lib64:/opt/slurm/slurm-20.11.0/lib64:\n",
      "2023-06-23 15:50:26.666037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'axial_positional_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28127/2521370348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maxial_positional_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxialPositionalEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#from vectorize_sum import one_hot_C, rev_comp_C, merge_read_counts_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'axial_positional_embedding'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pyBigWig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyfasta\n",
    "import pyranges as pr\n",
    "import math\n",
    "import yaml\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from axial_positional_embedding import AxialPositionalEmbedding\n",
    "\n",
    "#from vectorize_sum import one_hot_C, rev_comp_C, merge_read_counts_C\n",
    "\n",
    "#from numba import jit\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import statistics\n",
    "\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval, Variant\n",
    "\n",
    "import pyfaidx\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelSummary\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from math import pi, log\n",
    "\n",
    "import re\n",
    "from kipoiseq.extractors import VariantSeqExtractor\n",
    "from cyvcf2 import VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3e1a3-ecf0-4eef-91b0-a131572f7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def anti_join(x, y, on):\n",
    "    \"\"\"Return rows in x which are not present in y\"\"\"\n",
    "    ans = pd.merge(left=x, right=y, how='left', indicator=True, on=on)\n",
    "    ans = ans.loc[ans._merge == 'left_only', :].drop(columns='_merge')\n",
    "    return ans\n",
    "\n",
    "#24490\n",
    "idx_num = int(sys.argv[1]) - 1\n",
    "\n",
    "fasta_file = \"/gpfs/commons/home/tlin/data/enformer/hg38.fa\"\n",
    "\n",
    "metadata = '/sc/arion/work/lakhac01/ADSP_reguloML/train_dl_models/unsupervised_pretraining/test_kipoiseq/1000_metadata.tsv'\n",
    "sample_id_unrelated = '/sc/arion/projects/ad-omics/clakhani/1KG_phased/1000G_2504_high_coverage.sequence.index'\n",
    "cols = ['ENA_FILE_PATH',\n",
    "        'MD5SUM',\n",
    "        'RUN_ID',\n",
    "        'STUDY_ID',\n",
    "        'STUDY_NAME',\n",
    "        'CENTER_NAME',\n",
    "        'SUBMISSION_ID',\n",
    "        'SUBMISSION_DATE',\n",
    "        'SAMPLE_ID',\n",
    "        'SAMPLE_NAME',\n",
    "        'POPULATION',\n",
    "        'EXPERIMENT_ID',\n",
    "        'INSTRUMENT_PLATFORM',\n",
    "        'INSTRUMENT_MODEL',            \n",
    "        'LIBRARY_NAME',\n",
    "        'RUN_NAME',\n",
    "        'INSERT_SIZE',\n",
    "        'LIBRARY_LAYOUT',\n",
    "        'PAIRED_FASTQ',\n",
    "        'READ_COUNT',\n",
    "        'BASE_COUNT',\n",
    "        'ANALYSIS_GROUP'\n",
    "        ]\n",
    "\n",
    "environment = yaml.safe_load(open('../../../../environment.yml'))\n",
    "\n",
    "\n",
    "genome = pyfasta.Fasta(fasta_file)\n",
    "\n",
    "\n",
    "metadata = '/sc/arion/work/lakhac01/ADSP_reguloML/train_dl_models/unsupervised_pretraining/test_kipoiseq/1000_metadata.tsv'\n",
    "metadata_df = pd.read_csv(metadata, sep='\\t')\n",
    "\n",
    "metadata_df = metadata_df[['Sample name','Superpopulation name','Population name','Superpopulation code','Population code']]\n",
    "\n",
    "metadata_df = metadata_df.rename(columns={\"Sample name\": \"SAMPLE_NAME\",\n",
    "                                          \"Superpopulation name\": \"superpopulation_name\",\n",
    "                                          \"Population name\": \"population_name\",\n",
    "                                          \"Superpopulation code\": \"superpopulation_code\",\n",
    "                                          \"Population code\": \"population_code\",\n",
    "                                          })\n",
    "\n",
    "populations = metadata_df.population_code.unique().tolist()\n",
    "\n",
    "test_population = ['YRI']\n",
    "validation_population = ['CLM']\n",
    "test_validation_population = ['YRI','CLM']\n",
    "\n",
    "train_population = list(set(populations).difference(test_validation_population))\n",
    "\n",
    "\n",
    "\n",
    "black_list_bed = environment['minerva']['blacklist_regions_hg38']\n",
    "\n",
    "\n",
    "\n",
    "test_chromosomes = [\"chr9\"]\n",
    "validation_chromosomes = [\"chr5\"]\n",
    "train_chromosomes = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr6\", \"chr7\", \"chr8\", \"chr10\", \"chr11\", \"chr12\",\"chr13\",\n",
    "                     \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\"]\n",
    "\n",
    "\n",
    "\n",
    "all_chromosomes = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\",\n",
    "                   \"chr11\", \"chr12\",\"chr13\",\n",
    "                   \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\"]\n",
    "\n",
    "\n",
    "# sample_df = pd.read_csv(sample_id_unrelated, sep='\\t', comment='#',\n",
    "#                         header=None,\n",
    "#                         names=cols)\n",
    "\n",
    "# sample_df = sample_df[['SAMPLE_NAME']]\n",
    "\n",
    "\n",
    "# metadata_df = pd.read_csv(metadata, sep='\\t')\n",
    "\n",
    "# metadata_df = metadata_df[['Sample name','Superpopulation name','Population name','Superpopulation code','Population code']]\n",
    "\n",
    "# metadata_df = metadata_df.rename(columns={\"Sample name\": \"SAMPLE_NAME\",\n",
    "#                                           \"Superpopulation name\": \"superpopulation_name\",\n",
    "#                                           \"Population name\": \"population_name\",\n",
    "#                                           \"Superpopulation code\": \"superpopulation_code\",\n",
    "#                                           \"Population code\": \"population_code\",\n",
    "#                                           })\n",
    "\n",
    "# populations = metadata_df.population_code.unique().tolist()\n",
    "\n",
    "# test_population = ['YRI']\n",
    "# validation_population = ['CLM']\n",
    "# test_validation_population = ['YRI','CLM']\n",
    "\n",
    "# train_population = list(set(populations).difference(test_validation_population))\n",
    "\n",
    "\n",
    "\n",
    "# def scrub_string(s):\n",
    "#     s = s.strip()\n",
    "#     s = re.sub('[^0-9a-zA-Z]+', '', s)\n",
    "#     s = re.sub('[0-9]+', '', s)\n",
    "#     s = re.sub('[^ACGTN]', 'N', s)\n",
    "#     return s\n",
    "\n",
    "class SampleSeqExtractor(VariantSeqExtractor):\n",
    "    def __init__(self, fasta_file, vcf_file):\n",
    "        \"\"\"Sequence extractor which can extract an alternate sequence for a\n",
    "        given interval and the variants corresponding to a given\n",
    "        sample and phase.\n",
    "        Args:\n",
    "          fasta_file: Path to the fasta file containing the reference\n",
    "            sequence (can be gzipped)\n",
    "          vcf_file: Path to the VCF file containing phased genotype information\n",
    "        \"\"\"\n",
    "        self.vcf = VCF(vcf_file)\n",
    "        self._sample_indices = dict(zip(self.vcf.samples,\n",
    "                                        range(len(self.vcf.samples))))\n",
    "        super().__init__(fasta_file)\n",
    "    def extract(self, interval, sample, phase, anchor,\n",
    "                fixed_len=True, **kwargs):\n",
    "        \"\"\"Extracts an alternate sequence for a given interval and the\n",
    "        variants corresponding to a given sample.\n",
    "        Args:\n",
    "          interval: `kipoiseq.dataclasses.Interval`, Region of\n",
    "            interest from which to query the sequence. 0-based.\n",
    "          sample: `str`, Sample from the VCF file for which variants should be\n",
    "            extracted.\n",
    "          phase: `0` or `1`, Phase for which sequence should be extracted\n",
    "          anchor: `int`, Absolution position w.r.t. the interval\n",
    "            start. (0-based).  E.g. for an interval of `chr1:10-20`\n",
    "            the anchor of 10 denotes the point chr1:10 in the 0-based\n",
    "            coordinate system.\n",
    "          fixed_len: `bool`, If True, the return sequence will have the\n",
    "            same length as the `interval` (e.g. `interval.end -\n",
    "            interval.start`)\n",
    "          kwargs: Additional keyword arguments to pass to\n",
    "            `SampleSeqExtractor.extract`\n",
    "        Returns:\n",
    "          A single sequence (`str`) with all the variants applied.\n",
    "        \"\"\"\n",
    "        variants = []\n",
    "        if sample is not None:\n",
    "            if sample not in self.vcf.samples:\n",
    "                raise ValueError(f'Sample {sample} not present in VCF file')\n",
    "            if phase not in (0, 1):\n",
    "                raise ValueError('phase argument must be in (0, 1) if sample is not None')\n",
    "            # Interval is  0-based, cyvcf2 positions are 1-based: need to add 1\n",
    "            variants = self._get_sample_variants(\n",
    "                self.vcf(f'{interval.chrom}:'\n",
    "                    + f'{interval.start + 1}-{interval.end + 1}'\n",
    "                ),\n",
    "                sample,\n",
    "                phase\n",
    "            )\n",
    "        return super(SampleSeqExtractor, self).extract(\n",
    "            interval, variants, anchor, fixed_len, **kwargs)\n",
    "    def _get_sample_variants(self, variants, sample, phase):\n",
    "        \"\"\"Given a list of `cyvcf2.Variant`, returns all those present for a\n",
    "        given sample and phase and converts them to\n",
    "        `kipoiseq.dataclasses.Variant`\n",
    "        Args:\n",
    "          variants: List of `cyvcf2.Variant`, Variants of interest\n",
    "          sample: `str`, Sample for which to filter genotypes\n",
    "          phase: `0` or `1`, Phase for which to filter genotypes\n",
    "        Returns:\n",
    "          List of `kipoiseq.dataclasses.Variant`\n",
    "        \"\"\"\n",
    "        sample_index = self._sample_indices[sample]\n",
    "        return [\n",
    "            Variant.from_cyvcf(v) for v in variants\n",
    "            if v.genotypes[sample_index][phase]\n",
    "        ]\n",
    "\n",
    "\n",
    "## Change\n",
    "chromosomes = train_chromosomes\n",
    "context_length = 2 ** 19\n",
    "scaling_factor = 1\n",
    "#shift_range = 75000\n",
    "#train_list = []\n",
    "#val_list = []\n",
    "tile_list = []\n",
    "context_fourths = context_length//4\n",
    "shift_range = context_fourths // 2\n",
    "print(f'Context Length: {context_length}')\n",
    "for shift in [0, context_fourths * 1 , context_fourths * 2 , context_fourths * 3]:\n",
    "    print(shift)\n",
    "    blacklist_bed = pr.read_bed(black_list_bed)\n",
    "    chromsizes = pr.data.chromsizes()\n",
    "    tile = pr.gf.tile_genome(chromsizes, context_length)\n",
    "    tile.Start = tile.Start + shift\n",
    "    tile.End = tile.End + shift + shift_range\n",
    "    tile_black_list = tile.overlap(blacklist_bed, how='first')\n",
    "    #tile_df = tile.dfs\n",
    "    #tile_df = pd.concat(tile_df.values(), ignore_index=True)\n",
    "    tile = tile[tile.Chromosome.isin(chromosomes)].dfs\n",
    "    #val = tile[tile.Chromosome.isin(validation_chromosomes)].dfs\n",
    "    tile = pd.concat(tile.values(), ignore_index=True)\n",
    "    #val = pd.concat(val.values(), ignore_index=True)\n",
    "    tile_black_list_df = pd.concat(tile_black_list.dfs.values(), ignore_index=True)[['Chromosome', 'Start', 'End']]\n",
    "    tile = anti_join(tile, tile_black_list_df, on=['Chromosome', 'Start', 'End'])\n",
    "    tile_list.append(tile)\n",
    "    #val = anti_join(val, tile_black_list_df, on=['Chromosome', 'Start', 'End'])\n",
    "    #train_list.append(train)\n",
    "    #val_list.append(val)\n",
    "\n",
    "tile_all = pd.concat(tile_list, axis=0)\n",
    "len_tile_all = len(tile_all)\n",
    "\n",
    "tile_all['length'] = tile_all['End'] - tile_all['Start']\n",
    "\n",
    "tile_all = tile_all[tile_all['length'] == (context_length + shift_range)]\n",
    "tile_all.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#train = pd.concat(train_list, axis=0)\n",
    "#val = pd.concat(val_list, axis=0)\n",
    "#train.reset_index(inplace=True, drop=True)\n",
    "#val.reset_index(inplace=True, drop=True)\n",
    "#len_train = len(train)\n",
    "#len_val = len(val)\n",
    "\n",
    "print(\"All Length: {}\".format(len_tile_all))\n",
    "\n",
    "\n",
    "###Change\n",
    "population = train_population\n",
    "sample_df = sample_df.merge(metadata_df, on='SAMPLE_NAME')\n",
    "sample_df = sample_df[sample_df['population_code'].isin(population)]\n",
    "###Change\n",
    "split = 'train'\n",
    "sample_df\n",
    "chr_string = subset['Chromosome']\n",
    "vals = []\n",
    "count = 0\n",
    "len_df = len(sample_df)\n",
    "vcf = f\"/sc/arion/projects/ad-omics/clakhani/1KG_phased/CCDG_14151_B01_GRM_WGS_2020-08-05_{chr_string}.filtered.shapeit2-duohmm-phased.vcf.gz\"\n",
    "df_1KG = SampleSeqExtractor(fasta_file, vcf)\n",
    "\n",
    "interval = Interval(subset['Chromosome'], subset['Start'], subset['End'])\n",
    "center = interval.center() - interval.start\n",
    "print(interval)\n",
    "print(f'Count: {count} out of {len_df}')\n",
    "for sample_index, sample_row in sample_df.iterrows():\n",
    "    start = time.time()\n",
    "    print(sample_row['SAMPLE_NAME'])\n",
    "    seq1 = df_1KG.extract(interval, sample_row['SAMPLE_NAME'], 0, center, fixed_len=False)\n",
    "    seq2 = df_1KG.extract(interval, sample_row['SAMPLE_NAME'], 1, center, fixed_len=False)\n",
    "    seq1 = seq1.upper()\n",
    "    seq2 = seq2.upper()\n",
    "    seq1 = scrub_string(seq1)\n",
    "    seq2 = scrub_string(seq2)\n",
    "    dict_seq = {'Chromosome': subset['Chromosome'],\n",
    "                 'Start': subset['Start'],\n",
    "                 'End': subset['End'],\n",
    "                 'SAMPLE_NAME': sample_row['SAMPLE_NAME'],\n",
    "                 'super_population': sample_row['superpopulation_name'],\n",
    "                 'population': sample_row['population_name'],\n",
    "                 'superpopulation_code': sample_row['superpopulation_code'],\n",
    "                 'population_code': sample_row['population_code'],\n",
    "                 'seq_0': seq1,\n",
    "                 'len_seq_0': len(seq1),\n",
    "                 'pct_N_seq_0': seq1.count('N') / len(seq1),\n",
    "                 'seq_1': seq2,\n",
    "                 'len_seq_1': len(seq2),\n",
    "                 'pct_N_seq_1': seq2.count('N') / len(seq2)\n",
    "            }\n",
    "    vals.append(dict_seq)\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(f\"count: {count} out of {len_df} in {elapsed} seconds\")\n",
    "    count += 1\n",
    "\n",
    "output_df = pd.DataFrame(vals)\n",
    "\n",
    "output_df = output_df[output_df.pct_N_seq_0 <= .05]\n",
    "output_df = output_df[output_df.pct_N_seq_1 <= .05]\n",
    "\n",
    "#output_df = output_df[output_df.len_seq_0 >= context_length]\n",
    "#output_df = output_df[output_df.len_seq_1 >= context_length]\n",
    "\n",
    "output_df = output_df[[\"Chromosome\", \"Start\",\"End\",\"SAMPLE_NAME\",\"superpopulation_code\",\"population_code\",\"seq_0\",\"seq_1\"]]\n",
    "\n",
    "out_dir = f'/sc/arion/projects/ad-omics/clakhani/1KG_phased/training_data/{split}/'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "output_file = f\"{out_dir}/{split}_{chr_string}_chunk_{idx_num:05d}.tsv.gz\"\n",
    "\n",
    "print(output_df.shape)\n",
    "\n",
    "print(output_df.head())\n",
    "\n",
    "if len(output_df) != 0:\n",
    "    output_df.to_csv(output_file, sep='\\t', index=False, compression = 'gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0128437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def anti_join(x, y, on):\n",
    "    \"\"\"Return rows in x which are not present in y\"\"\"\n",
    "    ans = pd.merge(left=x, right=y, how='left', indicator=True, on=on)\n",
    "    ans = ans.loc[ans._merge == 'left_only', :].drop(columns='_merge')\n",
    "    return ans\n",
    "\n",
    "#24490\n",
    "idx_num = int(sys.argv[1]) - 1\n",
    "\n",
    "fasta_file = \"/gpfs/commons/home/tlin/data/enformer/hg38.fa\"\n",
    "\n",
    "metadata = '/sc/arion/work/lakhac01/ADSP_reguloML/train_dl_models/unsupervised_pretraining/test_kipoiseq/1000_metadata.tsv'\n",
    "sample_id_unrelated = '/sc/arion/projects/ad-omics/clakhani/1KG_phased/1000G_2504_high_coverage.sequence.index'\n",
    "cols = ['ENA_FILE_PATH',\n",
    "        'MD5SUM',\n",
    "        'RUN_ID',\n",
    "        'STUDY_ID',\n",
    "        'STUDY_NAME',\n",
    "        'CENTER_NAME',\n",
    "        'SUBMISSION_ID',\n",
    "        'SUBMISSION_DATE',\n",
    "        'SAMPLE_ID',\n",
    "        'SAMPLE_NAME',\n",
    "        'POPULATION',\n",
    "        'EXPERIMENT_ID',\n",
    "        'INSTRUMENT_PLATFORM',\n",
    "        'INSTRUMENT_MODEL',            \n",
    "        'LIBRARY_NAME',\n",
    "        'RUN_NAME',\n",
    "        'INSERT_SIZE',\n",
    "        'LIBRARY_LAYOUT',\n",
    "        'PAIRED_FASTQ',\n",
    "        'READ_COUNT',\n",
    "        'BASE_COUNT',\n",
    "        'ANALYSIS_GROUP'\n",
    "        ]\n",
    "\n",
    "environment = yaml.safe_load(open('../../../../environment.yml'))\n",
    "\n",
    "\n",
    "genome = pyfasta.Fasta(fasta_file)\n",
    "\n",
    "\n",
    "metadata = '/sc/arion/work/lakhac01/ADSP_reguloML/train_dl_models/unsupervised_pretraining/test_kipoiseq/1000_metadata.tsv'\n",
    "metadata_df = pd.read_csv(metadata, sep='\\t')\n",
    "\n",
    "metadata_df = metadata_df[['Sample name','Superpopulation name','Population name','Superpopulation code','Population code']]\n",
    "\n",
    "metadata_df = metadata_df.rename(columns={\"Sample name\": \"SAMPLE_NAME\",\n",
    "                                          \"Superpopulation name\": \"superpopulation_name\",\n",
    "                                          \"Population name\": \"population_name\",\n",
    "                                          \"Superpopulation code\": \"superpopulation_code\",\n",
    "                                          \"Population code\": \"population_code\",\n",
    "                                          })\n",
    "\n",
    "populations = metadata_df.population_code.unique().tolist()\n",
    "\n",
    "test_population = ['YRI']\n",
    "validation_population = ['CLM']\n",
    "test_validation_population = ['YRI','CLM']\n",
    "\n",
    "train_population = list(set(populations).difference(test_validation_population))\n",
    "\n",
    "\n",
    "\n",
    "black_list_bed = environment['minerva']['blacklist_regions_hg38']\n",
    "\n",
    "\n",
    "\n",
    "test_chromosomes = [\"chr9\"]\n",
    "validation_chromosomes = [\"chr5\"]\n",
    "train_chromosomes = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr6\", \"chr7\", \"chr8\", \"chr10\", \"chr11\", \"chr12\",\"chr13\",\n",
    "                     \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\"]\n",
    "\n",
    "\n",
    "\n",
    "all_chromosomes = [\"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\",\n",
    "                   \"chr11\", \"chr12\",\"chr13\",\n",
    "                   \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \"chr21\", \"chr22\"]\n",
    "\n",
    "\n",
    "# sample_df = pd.read_csv(sample_id_unrelated, sep='\\t', comment='#',\n",
    "#                         header=None,\n",
    "#                         names=cols)\n",
    "\n",
    "# sample_df = sample_df[['SAMPLE_NAME']]\n",
    "\n",
    "\n",
    "# metadata_df = pd.read_csv(metadata, sep='\\t')\n",
    "\n",
    "# metadata_df = metadata_df[['Sample name','Superpopulation name','Population name','Superpopulation code','Population code']]\n",
    "\n",
    "# metadata_df = metadata_df.rename(columns={\"Sample name\": \"SAMPLE_NAME\",\n",
    "#                                           \"Superpopulation name\": \"superpopulation_name\",\n",
    "#                                           \"Population name\": \"population_name\",\n",
    "#                                           \"Superpopulation code\": \"superpopulation_code\",\n",
    "#                                           \"Population code\": \"population_code\",\n",
    "#                                           })\n",
    "\n",
    "# populations = metadata_df.population_code.unique().tolist()\n",
    "\n",
    "# test_population = ['YRI']\n",
    "# validation_population = ['CLM']\n",
    "# test_validation_population = ['YRI','CLM']\n",
    "\n",
    "# train_population = list(set(populations).difference(test_validation_population))\n",
    "\n",
    "\n",
    "\n",
    "# def scrub_string(s):\n",
    "#     s = s.strip()\n",
    "#     s = re.sub('[^0-9a-zA-Z]+', '', s)\n",
    "#     s = re.sub('[0-9]+', '', s)\n",
    "#     s = re.sub('[^ACGTN]', 'N', s)\n",
    "#     return s\n",
    "\n",
    "class SampleSeqExtractor(VariantSeqExtractor):\n",
    "    def __init__(self, fasta_file, vcf_file):\n",
    "        \"\"\"Sequence extractor which can extract an alternate sequence for a\n",
    "        given interval and the variants corresponding to a given\n",
    "        sample and phase.\n",
    "        Args:\n",
    "          fasta_file: Path to the fasta file containing the reference\n",
    "            sequence (can be gzipped)\n",
    "          vcf_file: Path to the VCF file containing phased genotype information\n",
    "        \"\"\"\n",
    "        self.vcf = VCF(vcf_file)\n",
    "        self._sample_indices = dict(zip(self.vcf.samples,\n",
    "                                        range(len(self.vcf.samples))))\n",
    "        super().__init__(fasta_file)\n",
    "    def extract(self, interval, sample, phase, anchor,\n",
    "                fixed_len=True, **kwargs):\n",
    "        \"\"\"Extracts an alternate sequence for a given interval and the\n",
    "        variants corresponding to a given sample.\n",
    "        Args:\n",
    "          interval: `kipoiseq.dataclasses.Interval`, Region of\n",
    "            interest from which to query the sequence. 0-based.\n",
    "          sample: `str`, Sample from the VCF file for which variants should be\n",
    "            extracted.\n",
    "          phase: `0` or `1`, Phase for which sequence should be extracted\n",
    "          anchor: `int`, Absolution position w.r.t. the interval\n",
    "            start. (0-based).  E.g. for an interval of `chr1:10-20`\n",
    "            the anchor of 10 denotes the point chr1:10 in the 0-based\n",
    "            coordinate system.\n",
    "          fixed_len: `bool`, If True, the return sequence will have the\n",
    "            same length as the `interval` (e.g. `interval.end -\n",
    "            interval.start`)\n",
    "          kwargs: Additional keyword arguments to pass to\n",
    "            `SampleSeqExtractor.extract`\n",
    "        Returns:\n",
    "          A single sequence (`str`) with all the variants applied.\n",
    "        \"\"\"\n",
    "        variants = []\n",
    "        if sample is not None:\n",
    "            if sample not in self.vcf.samples:\n",
    "                raise ValueError(f'Sample {sample} not present in VCF file')\n",
    "            if phase not in (0, 1):\n",
    "                raise ValueError('phase argument must be in (0, 1) if sample is not None')\n",
    "            # Interval is  0-based, cyvcf2 positions are 1-based: need to add 1\n",
    "            variants = self._get_sample_variants(\n",
    "                self.vcf(f'{interval.chrom}:'\n",
    "                    + f'{interval.start + 1}-{interval.end + 1}'\n",
    "                ),\n",
    "                sample,\n",
    "                phase\n",
    "            )\n",
    "        return super(SampleSeqExtractor, self).extract(\n",
    "            interval, variants, anchor, fixed_len, **kwargs)\n",
    "    def _get_sample_variants(self, variants, sample, phase):\n",
    "        \"\"\"Given a list of `cyvcf2.Variant`, returns all those present for a\n",
    "        given sample and phase and converts them to\n",
    "        `kipoiseq.dataclasses.Variant`\n",
    "        Args:\n",
    "          variants: List of `cyvcf2.Variant`, Variants of interest\n",
    "          sample: `str`, Sample for which to filter genotypes\n",
    "          phase: `0` or `1`, Phase for which to filter genotypes\n",
    "        Returns:\n",
    "          List of `kipoiseq.dataclasses.Variant`\n",
    "        \"\"\"\n",
    "        sample_index = self._sample_indices[sample]\n",
    "        return [\n",
    "            Variant.from_cyvcf(v) for v in variants\n",
    "            if v.genotypes[sample_index][phase]\n",
    "        ]\n",
    "\n",
    "\n",
    "## Change\n",
    "chromosomes = train_chromosomes\n",
    "context_length = 2 ** 19\n",
    "scaling_factor = 1\n",
    "#shift_range = 75000\n",
    "#train_list = []\n",
    "#val_list = []\n",
    "tile_list = []\n",
    "context_fourths = context_length//4\n",
    "shift_range = context_fourths // 2\n",
    "print(f'Context Length: {context_length}')\n",
    "for shift in [0, context_fourths * 1 , context_fourths * 2 , context_fourths * 3]:\n",
    "    print(shift)\n",
    "    blacklist_bed = pr.read_bed(black_list_bed)\n",
    "    chromsizes = pr.data.chromsizes()\n",
    "    tile = pr.gf.tile_genome(chromsizes, context_length)\n",
    "    tile.Start = tile.Start + shift\n",
    "    tile.End = tile.End + shift + shift_range\n",
    "    tile_black_list = tile.overlap(blacklist_bed, how='first')\n",
    "    #tile_df = tile.dfs\n",
    "    #tile_df = pd.concat(tile_df.values(), ignore_index=True)\n",
    "    tile = tile[tile.Chromosome.isin(chromosomes)].dfs\n",
    "    #val = tile[tile.Chromosome.isin(validation_chromosomes)].dfs\n",
    "    tile = pd.concat(tile.values(), ignore_index=True)\n",
    "    #val = pd.concat(val.values(), ignore_index=True)\n",
    "    tile_black_list_df = pd.concat(tile_black_list.dfs.values(), ignore_index=True)[['Chromosome', 'Start', 'End']]\n",
    "    tile = anti_join(tile, tile_black_list_df, on=['Chromosome', 'Start', 'End'])\n",
    "    tile_list.append(tile)\n",
    "    #val = anti_join(val, tile_black_list_df, on=['Chromosome', 'Start', 'End'])\n",
    "    #train_list.append(train)\n",
    "    #val_list.append(val)\n",
    "\n",
    "tile_all = pd.concat(tile_list, axis=0)\n",
    "len_tile_all = len(tile_all)\n",
    "\n",
    "tile_all['length'] = tile_all['End'] - tile_all['Start']\n",
    "\n",
    "tile_all = tile_all[tile_all['length'] == (context_length + shift_range)]\n",
    "tile_all.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#train = pd.concat(train_list, axis=0)\n",
    "#val = pd.concat(val_list, axis=0)\n",
    "#train.reset_index(inplace=True, drop=True)\n",
    "#val.reset_index(inplace=True, drop=True)\n",
    "#len_train = len(train)\n",
    "#len_val = len(val)\n",
    "\n",
    "print(\"All Length: {}\".format(len_tile_all))\n",
    "\n",
    "\n",
    "###Change\n",
    "population = train_population\n",
    "sample_df = sample_df.merge(metadata_df, on='SAMPLE_NAME')\n",
    "sample_df = sample_df[sample_df['population_code'].isin(population)]\n",
    "###Change\n",
    "split = 'train'\n",
    "sample_df\n",
    "chr_string = subset['Chromosome']\n",
    "vals = []\n",
    "count = 0\n",
    "len_df = len(sample_df)\n",
    "vcf = f\"/sc/arion/projects/ad-omics/clakhani/1KG_phased/CCDG_14151_B01_GRM_WGS_2020-08-05_{chr_string}.filtered.shapeit2-duohmm-phased.vcf.gz\"\n",
    "df_1KG = SampleSeqExtractor(fasta_file, vcf)\n",
    "\n",
    "interval = Interval(subset['Chromosome'], subset['Start'], subset['End'])\n",
    "center = interval.center() - interval.start\n",
    "print(interval)\n",
    "print(f'Count: {count} out of {len_df}')\n",
    "for sample_index, sample_row in sample_df.iterrows():\n",
    "    start = time.time()\n",
    "    print(sample_row['SAMPLE_NAME'])\n",
    "    seq1 = df_1KG.extract(interval, sample_row['SAMPLE_NAME'], 0, center, fixed_len=False)\n",
    "    seq2 = df_1KG.extract(interval, sample_row['SAMPLE_NAME'], 1, center, fixed_len=False)\n",
    "    seq1 = seq1.upper()\n",
    "    seq2 = seq2.upper()\n",
    "    seq1 = scrub_string(seq1)\n",
    "    seq2 = scrub_string(seq2)\n",
    "    dict_seq = {'Chromosome': subset['Chromosome'],\n",
    "                 'Start': subset['Start'],\n",
    "                 'End': subset['End'],\n",
    "                 'SAMPLE_NAME': sample_row['SAMPLE_NAME'],\n",
    "                 'super_population': sample_row['superpopulation_name'],\n",
    "                 'population': sample_row['population_name'],\n",
    "                 'superpopulation_code': sample_row['superpopulation_code'],\n",
    "                 'population_code': sample_row['population_code'],\n",
    "                 'seq_0': seq1,\n",
    "                 'len_seq_0': len(seq1),\n",
    "                 'pct_N_seq_0': seq1.count('N') / len(seq1),\n",
    "                 'seq_1': seq2,\n",
    "                 'len_seq_1': len(seq2),\n",
    "                 'pct_N_seq_1': seq2.count('N') / len(seq2)\n",
    "            }\n",
    "    vals.append(dict_seq)\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(f\"count: {count} out of {len_df} in {elapsed} seconds\")\n",
    "    count += 1\n",
    "\n",
    "output_df = pd.DataFrame(vals)\n",
    "\n",
    "output_df = output_df[output_df.pct_N_seq_0 <= .05]\n",
    "output_df = output_df[output_df.pct_N_seq_1 <= .05]\n",
    "\n",
    "#output_df = output_df[output_df.len_seq_0 >= context_length]\n",
    "#output_df = output_df[output_df.len_seq_1 >= context_length]\n",
    "\n",
    "output_df = output_df[[\"Chromosome\", \"Start\",\"End\",\"SAMPLE_NAME\",\"superpopulation_code\",\"population_code\",\"seq_0\",\"seq_1\"]]\n",
    "\n",
    "out_dir = f'/sc/arion/projects/ad-omics/clakhani/1KG_phased/training_data/{split}/'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "output_file = f\"{out_dir}/{split}_{chr_string}_chunk_{idx_num:05d}.tsv.gz\"\n",
    "\n",
    "print(output_df.shape)\n",
    "\n",
    "print(output_df.head())\n",
    "\n",
    "if len(output_df) != 0:\n",
    "    output_df.to_csv(output_file, sep='\\t', index=False, compression = 'gzip')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enformer",
   "language": "python",
   "name": "enformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
